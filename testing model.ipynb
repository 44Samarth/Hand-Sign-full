{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Initialization**: Load the trained model (`model.p`) using pickle, initialize the MediaPipe Hands module for hand landmark detection, and define a dictionary mapping label indices to characters.\n",
    "\n",
    "2. **Webcam Initialization**: Start capturing video frames from the webcam using OpenCV.\n",
    "\n",
    "3. **Frame Processing**: Read a frame from the webcam, convert it to RGB color space, and process it to detect hand landmarks using the MediaPipe Hands module.\n",
    "\n",
    "4. **Hand Landmark Detection**: If hand landmarks are detected, draw them on the frame. Extract the normalized coordinates of hand landmarks and append them to the `data_aux` list.\n",
    "\n",
    "5. **Bounding Box and Label**: Determine the bounding box coordinates based on the detected hand landmarks and draw a bounding box around the detected hand gesture on the frame. Make predictions using the trained model based on the extracted hand landmark data. Display the predicted character label near the bounding box.\n",
    "\n",
    "6. **Display Frame**: Display the processed frame with the bounding box and predicted label.\n",
    "\n",
    "7. **User Input Handling**: Check for user input to exit the loop (`'q'` key).\n",
    "\n",
    "8. **Error Handling**: Catch any exceptions that occur during execution and print them.\n",
    "\n",
    "9. **Cleanup**: Release the webcam and close all OpenCV windows when the program ends.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pickle.load(open('./all_models/Random_Forest_Classifier_model.p', 'rb'))\n",
    "model = model_dict['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "# labels from 0 to 12\n",
    "labels_dict = {0:'A', 1:'B', 2:'C', 3:'D', 4:'E', 5:'F', 6:'G', 7:'H', 8:'I', 9:'J', 10:'K', 11:'L', 12:'M', 13:'N', 14:'O', 15:'P', 16:'Q', 17:'R', 18:'S', 19:'T', 20:'U', 21:'V', 22:'W', 23:'X', 24:'Y', 25:'Z'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mp_hands.Hands(): This creates an instance of the MediaPipe Hands module, which is used for detecting hand landmarks in images or video frames.\n",
    "\n",
    "- static_image_mode=True: This parameter indicates whether the module should process images as static images or video frames. When set to True, it indicates that the module will process static images (one-time analysis) rather than continuous video frames.\n",
    "\n",
    "- min_detection_confidence=0.3: This parameter sets the minimum confidence score required for a hand landmark to be considered detected. Hand landmarks with confidence scores below this threshold will be ignored. In this case, a confidence score of 0.3 is used, meaning that hand landmarks must have a confidence score of at least 30% to be considered valid detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Data and variables initialization\n",
    "        data_aux = []\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        # Read a frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Get the dimensions of the frame\n",
    "        H, W, _ = frame.shape\n",
    "\n",
    "        # Convert the frame to RGB color space\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the frame to detect hand landmarks\n",
    "        results = hands.process(frame_rgb)\n",
    "\n",
    "        # If hand landmarks are detected\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,  # image to draw\n",
    "                    hand_landmarks,  # model output\n",
    "                    mp_hands.HAND_CONNECTIONS,  # hand connections\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "\n",
    "                    x_.append(x)\n",
    "                    y_.append(y)\n",
    "\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x - min(x_))\n",
    "                    data_aux.append(y - min(y_))\n",
    "\n",
    "            x1 = int(min(x_) * W) - 10\n",
    "            y1 = int(min(y_) * H) - 10\n",
    "\n",
    "            x2 = int(max(x_) * W) - 10\n",
    "            y2 = int(max(y_) * H) - 10\n",
    "\n",
    "            # Make predictions using the model\n",
    "            prediction = model.predict([np.asarray(data_aux)])\n",
    "            prediction_prob = model.predict_proba([np.asarray(data_aux)])\n",
    "\n",
    "            # If predictions are available\n",
    "            if prediction.shape[0] > 0:\n",
    "                predicted_label_index = int(prediction[0])\n",
    "                predicted_character = labels_dict.get(predicted_label_index, \"Unknown\")\n",
    "                prediction_probability = np.max(prediction_prob)  # Get the maximum probability\n",
    "            \n",
    "            else:\n",
    "                predicted_character = \"Unknown\"\n",
    "                prediction_probability = 0.0  # Set probability to zero for unknown prediction\n",
    "\n",
    "\n",
    "            # Draw bounding box and label on the frame\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 4)\n",
    "            if prediction_probability > 0.2:\n",
    "                cv2.putText(frame, f'{predicted_character} ({prediction_probability:.2f})', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        # Check for user input to exit the loop\n",
    "        c = cv2.waitKey(1)\n",
    "        if c == ord('q'):\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        # Print the exception\n",
    "        print(\"An error occurred:\", str(e))\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "        cv2.imshow('frame', frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Handfeb17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
