{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train classiffier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loads hand gesture data from a pickle file.\n",
    "- Splits the data into training and testing sets.\n",
    "- Trains a Support Vector Classifier (SVC) model using the training data.\n",
    "- Evaluates the model's accuracy on the testing data.\n",
    "- Saves the trained model to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading Data: The script first loads the hand gesture data from a pickle file named 'data.pickle'. This file contains the preprocessed data, including the hand landmarks extracted from the images and their corresponding labels.\n",
    "\n",
    "* Splitting Data: After loading the data, it splits it into two sets: training data and testing data. The train_test_split function from scikit-learn is used for this purpose. By default, it splits the data into 80% training and 20% testing sets.\n",
    "\n",
    "* Model Initialization: Next, it initializes a Support Vector Classifier (SVC) model. SVC is a popular supervised learning algorithm used for classification tasks. In this case, it's chosen for its effectiveness in handling high-dimensional data like the hand landmarks extracted from images.\n",
    "\n",
    "* Model Training: The initialized SVC model is trained using the training data. The fit method is called on the model object (model.fit(x_train, y_train)), where x_train represents the features (hand landmarks) and y_train represents the corresponding labels.\n",
    "\n",
    "* Model Evaluation: Once the model is trained, it predicts the labels for the testing data using the predict method (y_predict = model.predict(x_test)). Then, it calculates the accuracy of the model by comparing the predicted labels (y_predict) with the actual labels (y_test). The accuracy_score function from scikit-learn is used for this purpose.\n",
    "\n",
    "* Saving the Model: Finally, the trained model is saved to a file named 'model.p' using pickle. This allows you to reuse the trained model later without needing to retrain it every time.\n",
    "\n",
    "* Print Results: The script prints the accuracy of the model on the testing data, indicating how well the model performs in classifying hand gestures. It also prints the percentage of samples that were classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC  # For SVC\n",
    "from sklearn.ensemble import RandomForestClassifier # For ensemble\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pickle.load(open('./data.pickle', 'rb')) # read the data from pickle file\n",
    "data = np.asarray(data_dict['data'])\n",
    "labels = np.asarray(data_dict['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9961538461538462\n",
      "Precision: 0.9965034965034967\n",
      "Recall: 0.9961538461538462\n",
      "F1-score: 0.9961442066705224\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "          10       1.00      1.00      1.00        20\n",
      "          11       1.00      1.00      1.00        20\n",
      "          12       1.00      1.00      1.00        20\n",
      "          13       1.00      1.00      1.00        20\n",
      "          14       1.00      1.00      1.00        20\n",
      "          15       1.00      1.00      1.00        20\n",
      "          16       1.00      1.00      1.00        20\n",
      "          17       1.00      1.00      1.00        20\n",
      "          18       0.91      1.00      0.95        20\n",
      "          19       1.00      1.00      1.00        20\n",
      "           2       1.00      1.00      1.00        20\n",
      "          20       1.00      1.00      1.00        20\n",
      "          21       1.00      1.00      1.00        20\n",
      "          22       1.00      1.00      1.00        20\n",
      "          23       1.00      1.00      1.00        20\n",
      "          24       1.00      1.00      1.00        20\n",
      "          25       1.00      1.00      1.00        20\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      0.90      0.95        20\n",
      "           5       1.00      1.00      1.00        20\n",
      "           6       1.00      1.00      1.00        20\n",
      "           7       1.00      1.00      1.00        20\n",
      "           8       1.00      1.00      1.00        20\n",
      "           9       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00       520\n",
      "   macro avg       1.00      1.00      1.00       520\n",
      "weighted avg       1.00      1.00      1.00       520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle=True, stratify=labels)\n",
    "x_train,x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42, shuffle=True, stratify=labels)\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "model = SVC(kernel='linear')  # You can choose different kernels like 'rbf' or 'poly' as well\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_predict, average='weighted')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_predict, average='weighted')\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_predict, average='weighted')\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "f = open('model.p', 'wb') # write the model to a file\n",
    "pickle.dump({'model': model}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### sklearn\n",
    "- User-Friendly Interface: scikit-learn provides a consistent and easy-to-use interface for various machine learning tasks, including classification, regression, clustering, dimensionality reduction, and more.\n",
    "\n",
    "- Wide Range of Algorithms: It implements a wide range of machine learning algorithms, including but not limited to:\n",
    "\n",
    "  - Supervised learning algorithms like Support Vector Machines (SVM), Decision Trees, Random Forests, Gradient Boosting, k-Nearest Neighbors (k-NN), and Neural Networks.\n",
    "  - Unsupervised learning algorithms like K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA), and Independent Component Analysis (ICA).\n",
    "\n",
    "- Model Evaluation and Validation: scikit-learn provides tools for model evaluation, including metrics such as accuracy, precision, recall, F1-score, ROC curves, and more. It also offers functions for cross-validation and hyperparameter tuning to improve model performance.\n",
    "\n",
    "- Data Preprocessing: The library includes various utilities for data preprocessing, such as feature scaling, feature selection, data imputation, encoding categorical variables, and handling missing values.\n",
    "\n",
    "- Integration with Other Libraries: scikit-learn seamlessly integrates with other popular Python libraries like NumPy, SciPy, Pandas, and Matplotlib, making it easy to incorporate machine learning into data analysis workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Handfeb17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
